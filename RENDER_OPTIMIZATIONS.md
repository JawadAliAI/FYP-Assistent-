# ‚úÖ Render Free Tier Optimization Plan (Completed)

## ‚ùå Problem: Out of Memory / Instability
The previous deployment crashed because **Whisper (base model) + PyTorch + FastAPI** exceeded the **512MB RAM** limit on Render's free tier. This caused "Connection Closed" errors on Chat and TTS endpoints.

## ‚úÖ Solution Implemented

### 1. Lazy Loading for Whisper
**What:** Removed global loading of Whisper on startup.
**Why:** The server now starts instantly using only ~100MB RAM. Whisper is ONLY loaded when you hit `/stt`.
**Result:** `/chat` and `/tts` endpoints are 100% stable and fast.

### 2. CPU-Optimized PyTorch
**What:** Updated `requirements.txt` to use `torch+cpu`.
**Why:** GPU libraries are huge (~700MB). CPU version is small (~150MB). Render free tier doesn't have a GPU anyway.
**Result:** Massive reduction in build size and memory usage.

### 3. Whisper "Tiny" Model
**What:** Configured `tiny` model (~75MB) instead of `base` (~140MB).
**Why:** Fits comfortably in valid memory relative to the 512MB limit.
**Result:** STT works without crashing the server.

---

## üöÄ How to Test (Once Redeployed)

The new build is currently deploying. Wait ~5-10 minutes, then:

### 1. Health Check (Instant)
```bash
curl https://fitbot-api-cks6.onrender.com/health
```

### 2. Chat (Fast & Stable)
```bash
curl -X POST https://fitbot-api-cks6.onrender.com/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello FitBot", "user_id": "test", "chat_history": []}'
```

### 3. TTS (Fast & Stable)
```bash
curl -X POST https://fitbot-api-cks6.onrender.com/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "Voice test", "voice": "en_US-lessac-medium"}'
```

### 4. STT (First Request Slower)
Note: The *first* request to `/stt` will take an extra 2-3 seconds to load the model into memory.
```bash
# Upload a file to test
```
